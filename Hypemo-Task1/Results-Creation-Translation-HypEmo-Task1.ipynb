{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78fc4f36-1be8-4e70-aba9-fbb0ea186624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "## Training set preperation\n",
    "dict_mapping = {'Presenting Irrelevant Data (Red Herring)': 0,\n",
    " 'Bandwagon': 1,\n",
    " 'Smears': 2,\n",
    " 'Glittering generalities (Virtue)': 3,\n",
    " 'Causal Oversimplification': 4,\n",
    " 'Whataboutism': 5,\n",
    " 'Loaded Language': 6,\n",
    " 'Exaggeration/Minimisation': 7,\n",
    " 'Repetition': 8,\n",
    " 'Thought-terminating clichÃ©': 9,\n",
    " 'Name calling/Labeling': 10,\n",
    " 'Appeal to authority': 11,\n",
    " 'Black-and-white Fallacy/Dictatorship': 12,\n",
    " 'Obfuscation, Intentional vagueness, Confusion': 13,\n",
    " 'Reductio ad hitlerum': 14,\n",
    " 'Appeal to fear/prejudice': 15,\n",
    " \"Misrepresentation of Someone's Position (Straw Man)\": 16,\n",
    " 'Flag-waving': 17,\n",
    " 'Slogans': 18,\n",
    " 'Doubt': 19,\n",
    " 'Bandwagon_1': 20,\n",
    " 'Whataboutism_1': 21,\n",
    " 'Appeal to fear/prejudice_1': 22,\n",
    " 'Flag-waving_1': 23,\n",
    " 'Appeal to authority_1': 24,\n",
    "}\n",
    "\n",
    "import numpy as np\n",
    "loaded_array = np.load('softmax_9_test_arey.npy')\n",
    "mapping_dict = {1: 20, 5: 21, 15: 22, 17: 23, 11: 24}\n",
    "for key in mapping_dict.keys():\n",
    "    duplicate_row = mapping_dict[key]\n",
    "    loaded_array[key] += loaded_array[int(duplicate_row)]\n",
    "loaded_array = loaded_array[:,:20]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "abnormal_peaks_per_row = []\n",
    "threshold = 1.5\n",
    "for row in loaded_array:\n",
    "    z_scores = np.abs((row - np.mean(row)) / np.std(row))\n",
    "    abnormal_peaks = list(np.where(z_scores > threshold)[0])\n",
    "    abnormal_peaks_per_row.append(abnormal_peaks)\n",
    "\n",
    "final_list = []\n",
    "idx2label = {idx: label for label, idx in dict_mapping.items()}\n",
    "for x in abnormal_peaks_per_row:\n",
    "    y = []\n",
    "    for d in x:\n",
    "        y.append(idx2label[d])\n",
    "    final_list.append(y)\n",
    "\n",
    "df_test_full['labels'] = final_list\\\n",
    "\n",
    "test_eng = df_test_full[1000:1000+1500]\n",
    "test_arab = df_test_full[1000+1500:1000+1500+100]\n",
    "test_bulg = df_test_full[1000+1500+100:1000+1500+100+436]\n",
    "test_mace = df_test_full[1000+1500+100+436:]\n",
    "#1000 + 1500 + 100 + 436 + 259\n",
    "\n",
    "def json_saving(df,json_file_path):\n",
    "    dict_list = []\n",
    "    columns_to_include = ['labels', 'id']\n",
    "    for index, row in df.iterrows():    \n",
    "        row_dict = {column: row[column] for column in columns_to_include}\n",
    "        dict_list.append(row_dict)\n",
    "    json_string = json.dumps(dict_list,indent = 2)\n",
    "    with open(json_file_path, 'w') as json_file:\n",
    "        json_file.write(json_string)\n",
    "    print(f'JSON data has been saved to: {json_file_path}')\n",
    "\n",
    "json_saving(test_eng,\"Hyp_emo_test_eng.json\")\n",
    "json_saving(test_arab,\"Hyp_emo_test_arab.json\")\n",
    "json_saving(test_bulg,\"Hyp_emo_test_bulg.json\")\n",
    "json_saving(test_mace,\"Hyp_emo_test_mace.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17924d8d-9af1-4849-9964-d2eafb7b2286",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
